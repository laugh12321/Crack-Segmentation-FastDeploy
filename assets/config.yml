gpu_id: 0
backend: TensorRT # Paddle, Paddle-TRT, TensorRT, ONNX
enable_fp16: True
model_dir: E:/Laugh/Projects/Crack-Segmentation-FastDeploy/assets/crack_inference_model/inference_model
max_batch_size: 6
set_shape:
  - tensor_name: x
    min: [1, 3, 1080, 1920]
    opt: [3, 3, 1080, 1920]
    max: [6, 3, 1080, 1920]